{"cells":[{"cell_type":"markdown","id":"d95f841a-63c9-41d4-aea1-496b3d2024dd","metadata":{"id":"d95f841a-63c9-41d4-aea1-496b3d2024dd"},"source":["**LLM Workshop 2024 by Sebastian Raschka**\n","\n","This code is based on *Build a Large Language Model (From Scratch)*, [https://github.com/rasbt/LLMs-from-scratch](https://github.com/rasbt/LLMs-from-scratch)"]},{"cell_type":"markdown","id":"K3lyhg-RKP3h","metadata":{"id":"K3lyhg-RKP3h"},"source":["# Setup"]},{"cell_type":"code","execution_count":null,"id":"pNnrVJzdKNHP","metadata":{"id":"pNnrVJzdKNHP"},"outputs":[],"source":["# Requirements from: https://github.com/rasbt/LLM-workshop-2024/blob/main/requirements.txt\n","requirements = \"\"\"\n","torch >= 2.0.1\n","tiktoken >= 0.5.1\n","matplotlib >= 3.7.1\n","numpy >= 1.24.3\n","tensorflow >= 2.15.0\n","tqdm >= 4.66.1\n","numpy >= 1.25, < 2.0\n","pandas >= 2.2.1\n","psutil >= 5.9.5\n","litgpt[all] >= 0.4.1\n","\"\"\"\n","\n","with open(\"requirements.txt\", mode=\"wt\") as f:\n","    f.write(requirements)\n","\n","%pip install -r requirements.txt --quiet"]},{"cell_type":"markdown","id":"25aa40e3-5109-433f-9153-f5770531fe94","metadata":{"id":"25aa40e3-5109-433f-9153-f5770531fe94"},"source":["# 2) Understanding LLM Input Data"]},{"cell_type":"markdown","id":"76d5d2c0-cba8-404e-9bf3-71a218cae3cf","metadata":{"id":"76d5d2c0-cba8-404e-9bf3-71a218cae3cf"},"source":["Packages that are being used in this notebook:"]},{"cell_type":"code","execution_count":1,"id":"4d1305cf-12d5-46fe-a2c9-36fb71c5b3d3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":174,"status":"ok","timestamp":1720534000133,"user":{"displayName":"Ryan Parker","userId":"18317737450322819970"},"user_tz":300},"id":"4d1305cf-12d5-46fe-a2c9-36fb71c5b3d3","outputId":"187bcff0-d4ee-4a08-f3db-2e87ba8d5022"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch version: 2.2.1+cu121\n","tiktoken version: 0.7.0\n"]}],"source":["from importlib.metadata import version\n","\n","\n","print(\"torch version:\", version(\"torch\"))\n","print(\"tiktoken version:\", version(\"tiktoken\"))"]},{"cell_type":"markdown","id":"5a42fbfd-e3c2-43c2-bc12-f5f870a0b10a","metadata":{"id":"5a42fbfd-e3c2-43c2-bc12-f5f870a0b10a"},"source":["- This notebook provides a brief overview of the data preparation and sampling procedures to get input data \"ready\" for an LLM\n","- Understanding what the input data looks like is a great first step towards understanding how LLMs work"]},{"cell_type":"markdown","id":"628b2922-594d-4ff9-bd82-04f1ebdf41f5","metadata":{"id":"628b2922-594d-4ff9-bd82-04f1ebdf41f5"},"source":["<img src=\"https://github.com/rasbt/LLM-workshop-2024/blob/main/02_data/figures/01.png?raw=1\" width=\"1000px\">"]},{"cell_type":"markdown","id":"eddbb984-8d23-40c5-bbfa-c3c379e7eec3","metadata":{"id":"eddbb984-8d23-40c5-bbfa-c3c379e7eec3"},"source":["<br>\n","<br>\n","<br>\n","<br>\n","\n","# 2.1 Tokenizing text"]},{"cell_type":"markdown","id":"f9c90731-7dc9-4cd3-8c4a-488e33b48e80","metadata":{"id":"f9c90731-7dc9-4cd3-8c4a-488e33b48e80"},"source":["- In this section, we tokenize text, which means breaking text into smaller units, such as individual words and punctuation characters"]},{"cell_type":"markdown","id":"09872fdb-9d4e-40c4-949d-52a01a43ec4b","metadata":{"id":"09872fdb-9d4e-40c4-949d-52a01a43ec4b"},"source":["<img src=\"https://github.com/rasbt/LLM-workshop-2024/blob/main/02_data/figures/02.png?raw=1\" width=\"800px\">"]},{"cell_type":"markdown","id":"8cceaa18-833d-46b6-b211-b20c53902805","metadata":{"id":"8cceaa18-833d-46b6-b211-b20c53902805"},"source":["- Load raw text we want to work with\n","- [The Verdict by Edith Wharton](https://en.wikisource.org/wiki/The_Verdict) is a public domain short story"]},{"cell_type":"code","execution_count":2,"id":"NZwwCZ3EM1om","metadata":{"id":"NZwwCZ3EM1om"},"outputs":[],"source":["import requests\n","\n","session = requests.Session()\n","with open(\"the-verdict.txt\", \"wt\", encoding=\"utf-8\") as f:\n","    response = session.get(\n","        \"https://raw.githubusercontent.com/rasbt/LLM-workshop-2024/main/02_data/the-verdict.txt\"\n","    )\n","    f.write(response.text)"]},{"cell_type":"code","execution_count":3,"id":"8a769e87-470a-48b9-8bdb-12841b416198","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":171,"status":"ok","timestamp":1720534009148,"user":{"displayName":"Ryan Parker","userId":"18317737450322819970"},"user_tz":300},"id":"8a769e87-470a-48b9-8bdb-12841b416198","outputId":"00fc60f6-2d2b-49a5-830a-bb95531c7a20"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total number of character: 20,479\n","I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"]}],"source":["with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n","    raw_text = f.read()\n","\n","print(f\"Total number of character: {len(raw_text):,d}\")\n","print(raw_text[:99])"]},{"cell_type":"markdown","id":"9b971a46-ac03-4368-88ae-3f20279e8f4e","metadata":{"id":"9b971a46-ac03-4368-88ae-3f20279e8f4e"},"source":["- The goal is to tokenize and embed this text for an LLM\n","- Let's develop a simple tokenizer based on some simple sample text that we can then later apply to the text above"]},{"cell_type":"markdown","id":"6cbe9330-b587-4262-be9f-497a84ec0e8a","metadata":{"id":"6cbe9330-b587-4262-be9f-497a84ec0e8a"},"source":["<img src=\"https://github.com/rasbt/LLM-workshop-2024/blob/main/02_data/figures/03.png?raw=1\" width=\"690px\">"]},{"cell_type":"markdown","id":"3daa1687-2c08-485a-87cc-a93c2f9586d7","metadata":{"id":"3daa1687-2c08-485a-87cc-a93c2f9586d7"},"source":["- The following regular expression will split on whitespaces and punctuation"]},{"cell_type":"code","execution_count":7,"id":"737dd5b0-9dbb-4a97-9ae4-3482c8c04be7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":176,"status":"ok","timestamp":1720534016085,"user":{"displayName":"Ryan Parker","userId":"18317737450322819970"},"user_tz":300},"id":"737dd5b0-9dbb-4a97-9ae4-3482c8c04be7","outputId":"be8c97c9-d3e4-4029-f7c7-047cd5249ecd"},"outputs":[{"name":"stdout","output_type":"stream","text":["['I', ' ', 'HAD', ' ', 'always', ' ', 'thought', ' ', 'Jack', ' ', 'Gisburn', ' ', 'rather', ' ', 'a', ' ', 'cheap', ' ', 'genius', '--', 'though', ' ', 'a', ' ', 'good', ' ', 'fellow', ' ', 'enough', '--', 'so', ' ', 'it', ' ', 'was', ' ', 'no', ' ']\n"]}],"source":["import re\n","\n","preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n","# preprocessed = [item for item in preprocessed if item]\n","print(preprocessed[:38])"]},{"cell_type":"code","execution_count":5,"id":"35db7b5e-510b-4c45-995f-f5ad64a8e19c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":171,"status":"ok","timestamp":1720534020314,"user":{"displayName":"Ryan Parker","userId":"18317737450322819970"},"user_tz":300},"id":"35db7b5e-510b-4c45-995f-f5ad64a8e19c","outputId":"33d9f177-715a-424b-bea5-d2341afab6aa"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of tokens: 8,405\n"]}],"source":["print(f\"Number of tokens: {len(preprocessed):,d}\")"]},{"cell_type":"markdown","id":"0b5ce8fe-3a07-4f2a-90f1-a0321ce3a231","metadata":{"id":"0b5ce8fe-3a07-4f2a-90f1-a0321ce3a231"},"source":["<br>\n","<br>\n","<br>\n","<br>\n","\n","# 2.2 Converting tokens into token IDs"]},{"cell_type":"markdown","id":"a5204973-f414-4c0d-87b0-cfec1f06e6ff","metadata":{"id":"a5204973-f414-4c0d-87b0-cfec1f06e6ff"},"source":["- Next, we convert the text tokens into token IDs that we can process via embedding layers later\n","- For this we first need to build a vocabulary"]},{"cell_type":"markdown","id":"177b041d-f739-43b8-bd81-0443ae3a7f8d","metadata":{"id":"177b041d-f739-43b8-bd81-0443ae3a7f8d"},"source":["<img src=\"https://github.com/rasbt/LLM-workshop-2024/blob/main/02_data/figures/04.png?raw=1\" width=\"900px\">"]},{"cell_type":"markdown","id":"8eeade64-037b-4b59-9039-d3b000ef8886","metadata":{"id":"8eeade64-037b-4b59-9039-d3b000ef8886"},"source":["- The vocabulary contains the unique words in the input text"]},{"cell_type":"code","execution_count":6,"id":"7fdf0533-5ab6-42a5-83fa-a3b045de6396","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1720534024295,"user":{"displayName":"Ryan Parker","userId":"18317737450322819970"},"user_tz":300},"id":"7fdf0533-5ab6-42a5-83fa-a3b045de6396","outputId":"110f3c84-d62e-4922-d9fb-c462df17e18a"},"outputs":[{"name":"stdout","output_type":"stream","text":["1,132 tokens\n"]}],"source":["all_words = sorted(set(preprocessed))\n","vocab_size = len(all_words)\n","\n","print(f\"{vocab_size:,d} tokens\")"]},{"cell_type":"code","execution_count":8,"id":"c1b039f1","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '--', '.', ':', ';', '?', 'A', 'Ah', 'Among', 'And', 'Are', 'Arrt', 'As']\n"]}],"source":["# Here are the first few tokens\n","print(all_words[:20])"]},{"cell_type":"code","execution_count":9,"id":"77d00d96-881f-4691-bb03-84fec2a75a26","metadata":{"id":"77d00d96-881f-4691-bb03-84fec2a75a26"},"outputs":[],"source":["vocab = {token: integer for integer, token in enumerate(all_words)}"]},{"cell_type":"markdown","id":"75bd1f81-3a8f-4dd9-9dd6-e75f32dacbe3","metadata":{"id":"75bd1f81-3a8f-4dd9-9dd6-e75f32dacbe3"},"source":["- Below are the first 50 entries in this vocabulary:"]},{"cell_type":"code","execution_count":11,"id":"e1c5de4a-aa4e-4aec-b532-10bb364039d6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1720534028778,"user":{"displayName":"Ryan Parker","userId":"18317737450322819970"},"user_tz":300},"id":"e1c5de4a-aa4e-4aec-b532-10bb364039d6","outputId":"80e9fca4-e92d-423e-c9ec-39ce14ea342d"},"outputs":[{"name":"stdout","output_type":"stream","text":["('\\n', 0)\n","(' ', 1)\n","('!', 2)\n","('\"', 3)\n","(\"'\", 4)\n","('(', 5)\n","(')', 6)\n","(',', 7)\n","('--', 8)\n","('.', 9)\n","(':', 10)\n","(';', 11)\n","('?', 12)\n","('A', 13)\n","('Ah', 14)\n","('Among', 15)\n","('And', 16)\n","('Are', 17)\n","('Arrt', 18)\n","('As', 19)\n","('At', 20)\n","('Be', 21)\n","('Begin', 22)\n","('Burlington', 23)\n","('But', 24)\n","('By', 25)\n","('Carlo', 26)\n","('Chicago', 27)\n","('Claude', 28)\n","('Come', 29)\n","('Croft', 30)\n","('Destroyed', 31)\n","('Devonshire', 32)\n","('Don', 33)\n","('Dubarry', 34)\n","('Emperors', 35)\n","('Florence', 36)\n","('For', 37)\n","('Gallery', 38)\n","('Gideon', 39)\n","('Gisburn', 40)\n","('Gisburns', 41)\n","('Grafton', 42)\n","('Greek', 43)\n","('Grindle', 44)\n","('Grindles', 45)\n","('HAD', 46)\n","('Had', 47)\n","('Hang', 48)\n","('Has', 49)\n","('He', 50)\n"]}],"source":["for i, item in enumerate(vocab.items()):\n","    print(item)\n","    if i >= 50:\n","        break"]},{"cell_type":"markdown","id":"3b1dc314-351b-476a-9459-0ec9ddc29b19","metadata":{"id":"3b1dc314-351b-476a-9459-0ec9ddc29b19"},"source":["- Below, we illustrate the tokenization of a short sample text using a small vocabulary:"]},{"cell_type":"code","execution_count":12,"id":"31-XCk7sQEZr","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":173,"status":"ok","timestamp":1720534034764,"user":{"displayName":"Ryan Parker","userId":"18317737450322819970"},"user_tz":300},"id":"31-XCk7sQEZr","outputId":"d044d707-0385-4c0e-b80c-af50ce32abca"},"outputs":[{"data":{"text/plain":["[99, 1, 586, 1, 117, 1, '[UNK]', 1, '[UNK]']"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# Quick test on converting the tokens into integer representations\n","new_text = re.split(r'([,.:;?_!\"()\\']|--|\\s)', \"This is a new sentence\")\n","[vocab.get(token, \"[UNK]\") for token in new_text]"]},{"cell_type":"markdown","id":"67407a9f-0202-4e7c-9ed7-1b3154191ebc","metadata":{"id":"67407a9f-0202-4e7c-9ed7-1b3154191ebc"},"source":["<img src=\"https://github.com/rasbt/LLM-workshop-2024/blob/main/02_data/figures/05.png?raw=1\" width=\"800px\">"]},{"cell_type":"markdown","id":"4e569647-2589-4c9d-9a5c-aef1c88a0a9a","metadata":{"id":"4e569647-2589-4c9d-9a5c-aef1c88a0a9a"},"source":["- Let's now put it all together into a tokenizer class"]},{"cell_type":"code","execution_count":13,"id":"f531bf46-7c25-4ef8-bff8-0d27518676d5","metadata":{"id":"f531bf46-7c25-4ef8-bff8-0d27518676d5"},"outputs":[],"source":["class SimpleTokenizerV1:\n","    def __init__(self, vocab):\n","        # Include a token for tokens not in the training dataset vocabulary\n","        vocab[\"[UNK]\"] = len(vocab)\n","        self.str_to_int = vocab\n","        self.int_to_str = {i: s for s, i in vocab.items()}\n","        self.unknown_token_int = self.str_to_int[\"[UNK]\"]  # same as len(vocab)\n","\n","    def encode(self, text):\n","        preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n","        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n","        ids = [self.str_to_int.get(s, self.unknown_token_int) for s in preprocessed]\n","        return ids\n","\n","    def decode(self, ids):\n","        text = \" \".join([self.int_to_str[i] for i in ids])\n","        # Replace spaces before the specified punctuations\n","        text = re.sub(r'\\s+([,.?!\"()\\'])', r\"\\1\", text)\n","        return text"]},{"cell_type":"markdown","id":"dee7a1e5-b54f-4ca1-87ef-3d663c4ee1e7","metadata":{"id":"dee7a1e5-b54f-4ca1-87ef-3d663c4ee1e7"},"source":["- The `encode` function turns text into token IDs\n","- The `decode` function turns token IDs back into text"]},{"cell_type":"markdown","id":"cc21d347-ec03-4823-b3d4-9d686e495617","metadata":{"id":"cc21d347-ec03-4823-b3d4-9d686e495617"},"source":["<img src=\"https://github.com/rasbt/LLM-workshop-2024/blob/main/02_data/figures/06.png?raw=1\" width=\"800px\">"]},{"cell_type":"markdown","id":"c2950a94-6b0d-474e-8ed0-66d0c3c1a95c","metadata":{"id":"c2950a94-6b0d-474e-8ed0-66d0c3c1a95c"},"source":["- We can use the tokenizer to encode (that is, tokenize) texts into integers\n","- These integers can then be embedded (later) as input of/for the LLM"]},{"cell_type":"code","execution_count":14,"id":"647364ec-7995-4654-9b4a-7607ccf5f1e4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":191,"status":"ok","timestamp":1720534053499,"user":{"displayName":"Ryan Parker","userId":"18317737450322819970"},"user_tz":300},"id":"647364ec-7995-4654-9b4a-7607ccf5f1e4","outputId":"a29a871a-521e-4759-91f3-ad4a40a8c57f"},"outputs":[{"name":"stdout","output_type":"stream","text":["[3, 58, 4, 852, 990, 604, 535, 748, 7, 1128, 598, 7, 3, 69, 9, 40, 853, 1110, 756, 795, 9]\n","\" It' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.\n"]}],"source":["tokenizer = SimpleTokenizerV1(vocab)\n","\n","text = \"\"\"\n","    \"It's the last he painted, you know,\"\n","    Mrs. Gisburn said with pardonable pride.\n","    \"\"\"\n","ids = tokenizer.encode(text)\n","print(ids)\n","print(tokenizer.decode(ids))"]},{"cell_type":"markdown","id":"3201706e-a487-4b60-b99d-5765865f29a0","metadata":{"id":"3201706e-a487-4b60-b99d-5765865f29a0"},"source":["- We can decode the integers back into text"]},{"cell_type":"code","execution_count":null,"id":"01d8c8fb-432d-4a49-b332-99f23b233746","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":190,"status":"ok","timestamp":1720534067147,"user":{"displayName":"Ryan Parker","userId":"18317737450322819970"},"user_tz":300},"id":"01d8c8fb-432d-4a49-b332-99f23b233746","outputId":"2a5e1648-f569-44ca-f438-fae4d0e95c9a"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\" It\\' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.'"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.decode(ids)"]},{"cell_type":"code","execution_count":null,"id":"54f6aa8b-9827-412e-9035-e827296ab0fe","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":236,"status":"ok","timestamp":1720534069761,"user":{"displayName":"Ryan Parker","userId":"18317737450322819970"},"user_tz":300},"id":"54f6aa8b-9827-412e-9035-e827296ab0fe","outputId":"ba779be9-1a83-4c11-a152-7cc79ceae668"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\" It\\' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.'"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.decode(tokenizer.encode(text))"]},{"cell_type":"code","execution_count":15,"id":"RLMK8fChSikT","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":196,"status":"ok","timestamp":1720534073676,"user":{"displayName":"Ryan Parker","userId":"18317737450322819970"},"user_tz":300},"id":"RLMK8fChSikT","outputId":"cc170363-8e53-4d56-c7b9-3c38fb5caa2d"},"outputs":[{"data":{"text/plain":["'This is a [UNK] [UNK]'"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.decode(tokenizer.encode(\"This is a new sentence\"))"]},{"cell_type":"markdown","id":"5c4ba34b-170f-4e71-939b-77aabb776f14","metadata":{"id":"5c4ba34b-170f-4e71-939b-77aabb776f14"},"source":["---\n","\n","# 2.3 BytePair encoding"]},{"cell_type":"markdown","id":"2309494c-79cf-4a2d-bc28-a94d602f050e","metadata":{"id":"2309494c-79cf-4a2d-bc28-a94d602f050e"},"source":["- GPT-2 used BytePair encoding (BPE) as its tokenizer\n","- it allows the model to break down words that aren't in its predefined vocabulary into smaller subword units or even individual characters, enabling it to handle out-of-vocabulary words\n","- For instance, if GPT-2's vocabulary doesn't have the word \"unfamiliarword,\" it might tokenize it as [\"unfam\", \"iliar\", \"word\"] or some other subword breakdown, depending on its trained BPE merges\n","- The original BPE tokenizer can be found here: [https://github.com/openai/gpt-2/blob/master/src/encoder.py](https://github.com/openai/gpt-2/blob/master/src/encoder.py)\n","- In this lecture, we are using the BPE tokenizer from OpenAI's open-source [tiktoken](https://github.com/openai/tiktoken) library, which implements its core algorithms in Rust to improve computational performance\n","- (Based on an analysis [here](https://github.com/rasbt/LLMs-from-scratch/blob/main/ch02/02_bonus_bytepair-encoder/compare-bpe-tiktoken.ipynb), I found that `tiktoken` is approx. 3x faster than the original tokenizer and 6x faster than an equivalent tokenizer in Hugging Face)"]},{"cell_type":"code","execution_count":null,"id":"ede1d41f-934b-4bf4-8184-54394a257a94","metadata":{"id":"ede1d41f-934b-4bf4-8184-54394a257a94"},"outputs":[],"source":["# pip install tiktoken"]},{"cell_type":"code","execution_count":16,"id":"48967a77-7d17-42bf-9e92-fc619d63a59e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":198,"status":"ok","timestamp":1720534085888,"user":{"displayName":"Ryan Parker","userId":"18317737450322819970"},"user_tz":300},"id":"48967a77-7d17-42bf-9e92-fc619d63a59e","outputId":"e40707b1-4a03-4226-ec7f-7182ad92bc2b"},"outputs":[{"name":"stdout","output_type":"stream","text":["tiktoken version: 0.7.0\n"]}],"source":["import importlib\n","import tiktoken\n","\n","print(\"tiktoken version:\", importlib.metadata.version(\"tiktoken\"))"]},{"cell_type":"code","execution_count":17,"id":"6ad3312f-a5f7-4efc-9d7d-8ea09d7b5128","metadata":{"id":"6ad3312f-a5f7-4efc-9d7d-8ea09d7b5128"},"outputs":[],"source":["tokenizer = tiktoken.get_encoding(\"gpt2\")"]},{"cell_type":"code","execution_count":18,"id":"5ff2cd85-7cfb-4325-b390-219938589428","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1720534090576,"user":{"displayName":"Ryan Parker","userId":"18317737450322819970"},"user_tz":300},"id":"5ff2cd85-7cfb-4325-b390-219938589428","outputId":"61a53729-98c6-4fd2-9c0b-9a097e405b68"},"outputs":[{"name":"stdout","output_type":"stream","text":["[15496, 11, 466, 345, 588, 1660, 45690, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 286, 617, 34680, 27271, 13]\n"]}],"source":["text = (\n","    \"Hello, do you like watermelon? <|endoftext|> In the sunlit terraces\"\n","    \" of someunknownPlace.\"\n",")\n","\n","integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n","\n","print(integers)"]},{"cell_type":"code","execution_count":19,"id":"d26a48bb-f82e-41a8-a955-a1c9cf9d50ab","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":193,"status":"ok","timestamp":1720534123238,"user":{"displayName":"Ryan Parker","userId":"18317737450322819970"},"user_tz":300},"id":"d26a48bb-f82e-41a8-a955-a1c9cf9d50ab","outputId":"cd8affc2-c426-463f-c97c-ed5a1dfc3ded"},"outputs":[{"name":"stdout","output_type":"stream","text":["Hello, do you like watermelon? <|endoftext|> In the sunlit terraces of someunknownPlace.\n"]}],"source":["strings = tokenizer.decode(integers)\n","\n","print(strings)"]},{"cell_type":"markdown","id":"e8c2e7b4-6a22-42aa-8e4d-901f06378d4a","metadata":{"id":"e8c2e7b4-6a22-42aa-8e4d-901f06378d4a"},"source":["- BPE tokenizers break down unknown words into subwords and individual characters:"]},{"cell_type":"markdown","id":"c082d41f-33d7-4827-97d8-993d5a84bb3c","metadata":{"id":"c082d41f-33d7-4827-97d8-993d5a84bb3c"},"source":["<img src=\"https://github.com/rasbt/LLM-workshop-2024/blob/main/02_data/figures/07.png?raw=1\" width=\"700px\">"]},{"cell_type":"code","execution_count":20,"id":"0beb27ee-1156-457c-839e-eebb48d94d0e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":190,"status":"ok","timestamp":1720534129873,"user":{"displayName":"Ryan Parker","userId":"18317737450322819970"},"user_tz":300},"id":"0beb27ee-1156-457c-839e-eebb48d94d0e","outputId":"32413a3a-7d91-4dbe-b8a8-a89b3867806d"},"outputs":[{"name":"stdout","output_type":"stream","text":["33901.....Ak\n","86........w\n","343.......ir\n","86........w\n","220....... \n","959.......ier\n"]}],"source":["for i in tokenizer.encode(\"Akwirw ier\", allowed_special={\"<|endoftext|>\"}):\n","    print(str(i).ljust(10, \".\"), tokenizer.decode([i]), sep=\"\")"]},{"cell_type":"code","execution_count":21,"id":"rLUwaaAtVFe0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":157,"status":"ok","timestamp":1720534178265,"user":{"displayName":"Ryan Parker","userId":"18317737450322819970"},"user_tz":300},"id":"rLUwaaAtVFe0","outputId":"1c8c4c4f-6646-4637-b46f-7daf61ef06be"},"outputs":[{"name":"stdout","output_type":"stream","text":["464_______The\n","40455_____ Hubble\n","10766_____ Deep\n","7663______ Field\n","2939______ image\n","14495_____ peers\n","656_______ into\n","262_______ the\n","46186_____ furthe\n","301_______st\n","12229_____ reaches\n","286_______ of\n","262_______ the\n","6881______ universe\n","986_______...\n"]}],"source":["for i in tokenizer.encode(\n","    \"The Hubble Deep Field image peers into the furthest reaches of the universe...\",\n","    allowed_special={\"<|endoftext|>\"},\n","):\n","    print(str(i).ljust(10, \"_\"), tokenizer.decode([i]), sep=\"\")"]},{"cell_type":"markdown","id":"abbd7c0d-70f8-4386-a114-907e96c950b0","metadata":{"id":"abbd7c0d-70f8-4386-a114-907e96c950b0"},"source":["<br>\n","<br>\n","<br>\n","<br>\n","\n","# 2.4 Data sampling with a sliding window"]},{"cell_type":"markdown","id":"509d9826-6384-462e-aa8a-a7c73cd6aad0","metadata":{"id":"509d9826-6384-462e-aa8a-a7c73cd6aad0"},"source":["- Above, we took care of the tokenization (converting text into word tokens represented as token ID numbers)\n","- Now, let's talk about how we create the data loading for LLMs\n","- We train LLMs to generate one word at a time, so we want to prepare the training data accordingly where the next word in a sequence represents the target to predict"]},{"cell_type":"markdown","id":"39fb44f4-0c43-4a6a-9c2f-9cf31452354c","metadata":{"id":"39fb44f4-0c43-4a6a-9c2f-9cf31452354c"},"source":["<img src=\"https://github.com/rasbt/LLM-workshop-2024/blob/main/02_data/figures/08.png?raw=1\" width=\"800px\">"]},{"cell_type":"markdown","id":"0c9a3d50-885b-49bc-b791-9f5cc8bc7b7c","metadata":{"id":"0c9a3d50-885b-49bc-b791-9f5cc8bc7b7c"},"source":["- For this, we use a sliding window approach, changing the position by +1:\n","\n","<img src=\"https://github.com/rasbt/LLM-workshop-2024/blob/main/02_data/figures/09.png?raw=1\" width=\"900px\">"]},{"cell_type":"markdown","id":"b006212f-de45-468d-bdee-5806216d1679","metadata":{"id":"b006212f-de45-468d-bdee-5806216d1679"},"source":["- Note that in practice it's best to set the stride equal to the context length so that we don't have overlaps between the inputs (the targets are still shifted by +1 always)"]},{"cell_type":"markdown","id":"9cb467e0-bdcd-4dda-b9b0-a738c5d33ac3","metadata":{"id":"9cb467e0-bdcd-4dda-b9b0-a738c5d33ac3"},"source":["<img src=\"https://github.com/rasbt/LLM-workshop-2024/blob/main/02_data/figures/10.png?raw=1\" width=\"800px\">"]},{"cell_type":"code","execution_count":22,"id":"mACUX3dbYP6I","metadata":{"id":"mACUX3dbYP6I"},"outputs":[],"source":["session = requests.Session()\n","with open(\"custom_dataloader.py\", \"wt\", encoding=\"utf-8\") as f:\n","    response = session.get(\n","        \"https://raw.githubusercontent.com/rasbt/LLM-workshop-2024/main/02_data/supplementary.py\"\n","    )\n","    f.write(response.text)"]},{"cell_type":"code","execution_count":23,"id":"fb55f51a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6079,"status":"ok","timestamp":1720534268696,"user":{"displayName":"Ryan Parker","userId":"18317737450322819970"},"user_tz":300},"id":"fb55f51a","outputId":"3b9f6be1-9359-4a66-8b6d-9b2f3c6ebe4d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Inputs:\n"," tensor([[   40,   367,  2885,  1464],\n","        [ 1807,  3619,   402,   271],\n","        [10899,  2138,   257,  7026],\n","        [15632,   438,  2016,   257],\n","        [  922,  5891,  1576,   438],\n","        [  568,   340,   373,   645],\n","        [ 1049,  5975,   284,   502],\n","        [  284,  3285,   326,    11]])\n","\n","Targets:\n"," tensor([[  367,  2885,  1464,  1807],\n","        [ 3619,   402,   271, 10899],\n","        [ 2138,   257,  7026, 15632],\n","        [  438,  2016,   257,   922],\n","        [ 5891,  1576,   438,   568],\n","        [  340,   373,   645,  1049],\n","        [ 5975,   284,   502,   284],\n","        [ 3285,   326,    11,   287]])\n"]}],"source":["from custom_dataloader import create_dataloader_v1\n","\n","\n","dataloader = create_dataloader_v1(\n","    raw_text, batch_size=8, max_length=4, stride=4, shuffle=False\n",")\n","\n","data_iter = iter(dataloader)\n","inputs, targets = next(data_iter)\n","print(\"Inputs:\\n\", inputs)\n","print(\"\\nTargets:\\n\", targets)"]},{"cell_type":"markdown","id":"2dc671fb-6945-4594-b33f-8b462a69720d","metadata":{"id":"2dc671fb-6945-4594-b33f-8b462a69720d"},"source":["<br>\n","<br>\n","<br>\n","<br>\n","\n","# Exercise: Prepare your own favorite text dataset"]},{"cell_type":"markdown","id":"-SK0ePExZYy-","metadata":{"id":"-SK0ePExZYy-"},"source":["Dataset: Jane Austen's books, from Project Gutenberg"]},{"cell_type":"code","execution_count":24,"id":"pL_sjwOaZW26","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5393,"status":"ok","timestamp":1720534398102,"user":{"displayName":"Ryan Parker","userId":"18317737450322819970"},"user_tz":300},"id":"pL_sjwOaZW26","outputId":"2849a3f8-461b-4514-fe04-b15234abe492"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total number of characters: 4,268,236\n"]}],"source":["import re  # regular expressions, for extracting text from books\n","import requests  # for accessing books from URLs\n","from pathlib import Path  # for creating a directory to store books\n","\n","def get_jane_austen_book_text():\n","    \"\"\"Return the full text of Jane Austen's books on Project Gutenberg\"\"\"\n","    book_names = [\n","        \"Pride and Prejudice\",\n","        \"Emma\",\n","        \"Sense and Sensibility\",\n","        \"Persuasion\",\n","        \"Northanger Abbey\",\n","        \"Mansfield Park\",\n","        \"Lady Susan\",\n","    ]\n","\n","    book_urls = [\n","        \"https://www.gutenberg.org/files/1342/1342-0.txt\",\n","        \"https://www.gutenberg.org/cache/epub/158/pg158.txt\",\n","        \"https://www.gutenberg.org/files/161/161-0.txt\",\n","        \"https://www.gutenberg.org/cache/epub/105/pg105.txt\",\n","        \"https://www.gutenberg.org/files/121/121-0.txt\",\n","        \"https://www.gutenberg.org/files/141/141-0.txt\",\n","        \"https://www.gutenberg.org/cache/epub/946/pg946.txt\",\n","    ]\n","\n","    # Create a folder to save the books in\n","    book_directory = Path(\"./books/\")\n","    if not book_directory.exists():\n","        book_directory.mkdir()\n","\n","    jane_austen_full_text = \"\"\n","\n","    session = requests.Session()\n","\n","    # Save books to a folder so they can be accessed later if needed\n","    # Also save the entire text in the jane_austen_full_text variable\n","    for num, url in enumerate(book_urls):\n","        response = session.get(url)\n","        # Ensure the response text is properly formatted as utf-8\n","        # See: https://stackoverflow.com/a/44203507/17005348\n","        response.encoding = \"UTF-8\"\n","        book_text = response.text\n","        book_title = book_names[num].replace(\" \", \"_\")\n","        with open(f\"./books/{book_title}.txt\", mode=\"w+\", encoding=\"utf-8\") as book_file:\n","            book_file.write(book_text)\n","\n","        # Save the text to the jane_austen_full_text variable,\n","        # removing the intro and end parts from Project Gutenberg\n","        # which have this form: *** BEGIN BOOK *** or *** END OF BOOK ***\n","        jane_austen_full_text += re.split(r\"[*]{3}.*?[*]{3}\", string=book_text)[1]\n","\n","    with open(\"./books/jane_austen.txt\", mode=\"w+\", encoding=\"utf-8\") as book_file:\n","        book_file.write(jane_austen_full_text)\n","    \n","    print(\"Full text saved to: ./books/jane_austen.txt\")\n","    print(f\"Total number of characters: {len(jane_austen_full_text):,d}\")\n","    return jane_austen_full_text\n","\n","jane_austen_full_text = get_jane_austen_book_text()"]},{"cell_type":"code","execution_count":25,"id":"D9CpTotq115X","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5753,"status":"ok","timestamp":1720534801153,"user":{"displayName":"Ryan Parker","userId":"18317737450322819970"},"user_tz":300},"id":"D9CpTotq115X","outputId":"4106b340-5440-49e5-f1c8-72b4c442f9da"},"outputs":[{"name":"stdout","output_type":"stream","text":["Inputs:\n"," tensor([[  201,   198,   201,   198,   201,   198,   201,   198],\n","        [  201,   198,   220,   220,   220,   220,   220,   220],\n","        [  220,   220,   220,   220,   220,   220,   220,   220],\n","        [  220,   220,   220,   220,   220,   220,   220,   220],\n","        [  220,   220,   220,   220,   220,   685, 21478, 44027],\n","        [   25,   201,   198,   201,   198,   220,   220,   220],\n","        [  220,   220,   220,   220,   220,   220,   220,   220],\n","        [  220,   220,   220,   220,   220,   220,   220,   220]])\n","\n","Targets:\n"," tensor([[  198,   201,   198,   201,   198,   201,   198,   201],\n","        [  198,   220,   220,   220,   220,   220,   220,   220],\n","        [  220,   220,   220,   220,   220,   220,   220,   220],\n","        [  220,   220,   220,   220,   220,   220,   220,   220],\n","        [  220,   220,   220,   220,   685, 21478, 44027,    25],\n","        [  201,   198,   201,   198,   220,   220,   220,   220],\n","        [  220,   220,   220,   220,   220,   220,   220,   220],\n","        [  220,   220,   220,   220,   220,   220,   220,   220]])\n"]}],"source":["dataloader = create_dataloader_v1(\n","    jane_austen_full_text, batch_size=8, max_length=8, stride=8, shuffle=False\n",")\n","\n","data_iter = iter(dataloader)\n","inputs, targets = next(data_iter)\n","print(\"Inputs:\\n\", inputs)\n","print(\"\\nTargets:\\n\", targets)"]},{"cell_type":"code","execution_count":null,"id":"Q6saJecA3YOC","metadata":{"id":"Q6saJecA3YOC"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/rasbt/LLM-workshop-2024/blob/main/02_data/02.ipynb","timestamp":1720472570057}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":5}
